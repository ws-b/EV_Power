{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import plotly.graph_objects as go\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.interpolate import griddata\n",
        "from GS_vehicle_dict import vehicle_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_split_data(base_dir, vehicle_dict, train_count=500, test_count=120, test_ratio=0.2):\n",
        "    all_files = []\n",
        "\n",
        "    for vehicle, ids in vehicle_dict.items():\n",
        "        for vid in ids:\n",
        "            patterns = [\n",
        "                os.path.join(base_dir, f\"**/bms_{vid}-*\"),\n",
        "                os.path.join(base_dir, f\"**/bms_altitude_{vid}-*\")\n",
        "            ]\n",
        "            for pattern in patterns:\n",
        "                all_files += glob.glob(pattern, recursive=True)\n",
        "\n",
        "    random.shuffle(all_files)\n",
        "\n",
        "    if test_ratio is not None:\n",
        "        split_index = int(len(all_files) * (1 - test_ratio))\n",
        "        train_files = all_files[:split_index]\n",
        "        test_files = all_files[split_index:]\n",
        "        print(f\"Total files: {len(all_files)}\")\n",
        "    else:\n",
        "        train_files = all_files[:train_count]\n",
        "        test_files = all_files[train_count:train_count + test_count]\n",
        "\n",
        "    return train_files, test_files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_files(files):\n",
        "    df_list = []\n",
        "    out_of_range_files = []\n",
        "    for file in files:\n",
        "        try:\n",
        "            data = pd.read_csv(file)\n",
        "            if 'Power' in data.columns and 'Power_IV' in data.columns:\n",
        "                if data['acceleration'].abs().max() > 9.8:\n",
        "                    out_of_range_files.append(file)\n",
        "                data['Residual'] = data['Power_IV'] - data['Power']\n",
        "                df_list.append(data[['speed', 'acceleration', 'Residual']])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file}: {e}\")\n",
        "    if out_of_range_files:\n",
        "        print(\"Out-of-range acceleration values detected in the following files:\")\n",
        "        for f in out_of_range_files:\n",
        "            print(f)\n",
        "    full_data = pd.concat(df_list, ignore_index=True)\n",
        "    scaler = StandardScaler()\n",
        "    full_data[['speed', 'acceleration']] = scaler.fit_transform(full_data[['speed', 'acceleration']])\n",
        "    return full_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def custom_objective(y_pred, dtrain):\n",
        "    y_true = dtrain.get_label()\n",
        "    grad = y_pred - y_true\n",
        "    hess = np.ones_like(y_true)\n",
        "\n",
        "    # Get the speed feature from the DMatrix\n",
        "    speed = dtrain.get_float_info('base_margin')\n",
        "    \n",
        "    # Ensure that the speed array has the correct shape\n",
        "    if speed.shape[0] != y_pred.shape[0]:\n",
        "        print(f\"Speed shape: {speed.shape}, y_pred shape: {y_pred.shape}\")\n",
        "        raise ValueError(\"Mismatch in shape between speed and y_pred\")\n",
        "\n",
        "    # Identify where speed is zero and the predicted power would be negative\n",
        "    mask = (speed == 0) & (y_pred < y_true)\n",
        "    grad[mask] += 10 * (y_pred[mask] - y_true[mask])  # Increase gradient penalty\n",
        "    hess[mask] *= 10  # Increase hessian penalty\n",
        "\n",
        "    return grad, hess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / (y_true + np.finfo(float).eps))) * 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_3d(X, y_true, y_pred):\n",
        "    # Check data shapes and types\n",
        "    print(f\"X shape: {X.shape}, y_true shape: {y_true.shape}, y_pred shape: {y_pred.shape}\")\n",
        "    \n",
        "    if not isinstance(X, np.ndarray) or not isinstance(y_true, np.ndarray) or not isinstance(y_pred, np.ndarray):\n",
        "        print(\"Error: X, y_true, or y_pred is not a numpy array.\")\n",
        "        return\n",
        "    \n",
        "    if X.shape[1] != 2:\n",
        "        print(\"Error: X should have 2 columns.\")\n",
        "        return\n",
        "\n",
        "    # Ensure that the data used for interpolation does not have extreme values\n",
        "    print(f\"Acceleration range before filtering: {X[:, 1].min()} to {X[:, 1].max()}\")\n",
        "    assert X[:, 1].min() >= -9.8 and X[:, 1].max() <= 9.8, \"Acceleration values out of range detected!\"\n",
        "\n",
        "    # Randomly sample 1000 points or less if there are fewer rows\n",
        "    sample_size = min(1000, X.shape[0])\n",
        "    sample_indices = np.random.choice(X.shape[0], sample_size, replace=False)\n",
        "    X_sampled = X[sample_indices]\n",
        "    y_true_sampled = y_true[sample_indices]\n",
        "    y_pred_sampled = y_pred[sample_indices]\n",
        "\n",
        "    # Create the scatter plot for actual residuals\n",
        "    trace1 = go.Scatter3d(\n",
        "        x=X_sampled[:, 0], y=X_sampled[:, 1], z=y_true_sampled,\n",
        "        mode='markers',\n",
        "        marker=dict(size=5, color='blue', opacity=0.8),\n",
        "        name='Actual Residual'\n",
        "    )\n",
        "\n",
        "    # Create the scatter plot for predicted residuals\n",
        "    trace2 = go.Scatter3d(\n",
        "        x=X_sampled[:, 0], y=X_sampled[:, 1], z=y_pred_sampled,\n",
        "        mode='markers',\n",
        "        marker=dict(size=5, color='red', opacity=0.8),\n",
        "        name='Predicted Residual'\n",
        "    )\n",
        "\n",
        "    # Generate a grid for surface plot\n",
        "    grid_x, grid_y = np.linspace(min(X[:, 0]), max(X[:, 0]), 100), np.linspace(min(X[:, 1]), max(X[:, 1]), 100)\n",
        "    grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
        "\n",
        "    # Perform griddata interpolation\n",
        "    grid_z = griddata((X[:, 0], X[:, 1]), y_pred, (grid_x, grid_y), method='linear')\n",
        "    \n",
        "    # Ensure no values in grid_z exceed expected range\n",
        "    print(f\"Interpolated Z values range: {grid_z.min()} to {grid_z.max()}\")\n",
        "\n",
        "    # Create a surface plot for predicted residuals\n",
        "    surface_trace = go.Surface(\n",
        "        x=grid_x,\n",
        "        y=grid_y,\n",
        "        z=grid_z,\n",
        "        colorscale='Viridis',\n",
        "        name='Predicted Residual Surface',\n",
        "        opacity=0.7\n",
        "    )\n",
        "\n",
        "    data = [trace1, trace2, surface_trace]\n",
        "    layout = go.Layout(\n",
        "        margin=dict(l=0, r=0, b=0, t=0),\n",
        "        scene=dict(\n",
        "            xaxis=dict(title='Speed'),\n",
        "            yaxis=dict(title='Acceleration'),\n",
        "            zaxis=dict(title='Residual'),\n",
        "        ),\n",
        "        title='3D Plot of Actual vs. Predicted Residuals'\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_full_time_series(data, y_pred, file_name):\n",
        "    data['time'] = pd.to_datetime(data['time'])\n",
        "    predicted_power = data['Power_IV'] - y_pred\n",
        "    interval = (data['time'].diff().dt.total_seconds().fillna(0) / 3600)\n",
        "    Actual_Energy = np.cumsum(data['Power_IV'] / 1000 * interval)\n",
        "    Model_Energy = np.cumsum(data['Power'] / 1000 * interval)\n",
        "    Predicted_Energy = np.cumsum(predicted_power / 1000 * interval)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "    ax1.set_title('Actual vs Predicted Power over Time')\n",
        "    ax1.plot(data['time'], data['Power_IV'] / 1000, label='Actual Power_IV (kW)', color='blue')\n",
        "    ax1.plot(data['time'], data['Predicted_Power'] / 1000, label='Predicted Power (kW)', color='red')\n",
        "    ax1.plot(data['time'], data['Power'] / 1000, label='Model Power (kW)', color='green')\n",
        "    ax1.set_xlabel('Time')\n",
        "    ax1.set_ylabel('Power (kW)')\n",
        "    ax1.legend(loc='upper left', bbox_to_anchor=(0, 0.95))\n",
        "    ax1.grid(True)\n",
        "    date = data['time'].iloc[0].strftime('%Y-%m-%d')\n",
        "    ax1.text(0.99, 0.98, date, transform=ax1.transAxes, fontsize=12, verticalalignment='top',\n",
        "             horizontalalignment='right', color='black')\n",
        "    ax1.text(0.01, 0.98, f'File: {file_name}', transform=ax1.transAxes, fontsize=10, verticalalignment='top',\n",
        "             horizontalalignment='left', color='black')\n",
        "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "\n",
        "    ax2.set_title('Actual vs Predicted Energy over Time')\n",
        "    ax2.plot(data['time'], Actual_Energy, label='Actual Energy (kWh)', color='blue')\n",
        "    ax2.plot(data['time'], Predicted_Energy, label='Predicted Energy (kWh)', color='red')\n",
        "    ax2.plot(data['time'], Model_Energy, label='Model Energy (kWh)', color='tab:green')\n",
        "    ax2.set_xlabel('Time')\n",
        "    ax2.set_ylabel('Energy (kWh)')\n",
        "    ax2.legend(loc='upper left', bbox_to_anchor=(0, 0.95))\n",
        "    ax2.grid(True)\n",
        "    ax2.text(0.99, 0.98, date, transform=ax2.transAxes, fontsize=12, verticalalignment='top',\n",
        "             horizontalalignment='right', color='black')\n",
        "    ax2.text(0.01, 0.98, f'File: {file_name}', transform=ax2.transAxes, fontsize=10, verticalalignment='top',\n",
        "             horizontalalignment='left', color='black')\n",
        "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "\n",
        "    if 'altitude' in data.columns:\n",
        "        data.set_index('time', inplace=True)\n",
        "        data_resampled = data.resample('1T').mean()\n",
        "        ax2_alt = ax2.twinx()\n",
        "        ax2_alt.set_ylabel('Altitude (m)')\n",
        "        ax2_alt.plot(data_resampled.index, data_resampled['altitude'], label='Altitude (m)', color='tab:orange',\n",
        "                     linestyle='-')\n",
        "        ax2_alt.legend(loc='upper right', bbox_to_anchor=(1, 0.97))\n",
        "        data.reset_index(inplace=True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    base_dir = os.path.normpath(r'D:\\SamsungSTF\\Processed_Data\\TripByTrip')\n",
        "\n",
        "    # Load and process data\n",
        "    train_files, test_files = load_and_split_data(base_dir, vehicle_dict)\n",
        "    train_data = process_files(train_files)\n",
        "    test_data = process_files(test_files)\n",
        "\n",
        "    # Prepare data for XGBoost\n",
        "    X_train = train_data[['speed', 'acceleration']].to_numpy()\n",
        "    y_train = train_data['Residual'].to_numpy()\n",
        "    X_test = test_data[['speed', 'acceleration']].to_numpy()\n",
        "    y_test = test_data['Residual'].to_numpy()\n",
        "\n",
        "    # Include speed as a feature and base margin\n",
        "    base_margin_train = train_data['speed'].to_numpy()\n",
        "    base_margin_test = test_data['speed'].to_numpy()\n",
        "\n",
        "    # Initialize DMatrix for XGBoost\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train, base_margin=base_margin_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test, base_margin=base_margin_test)\n",
        "\n",
        "    # Define XGBoost parameters\n",
        "    params = {\n",
        "        'tree_method': 'hist',\n",
        "        'device': 'cuda',\n",
        "        'eval_metric': 'rmse'\n",
        "    }\n",
        "\n",
        "    # Training with custom objective function\n",
        "    evals = [(dtrain, 'train'), (dtest, 'test')]\n",
        "    model = xgb.train(params, dtrain, num_boost_round=100, evals=evals, obj=custom_objective)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(dtest)\n",
        "\n",
        "    # Calculate MAPE, RMSE\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    print(f\"Test MAPE for Residual Prediction: {mape:.2f}%\")\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    print(f\"Test RMSE for Residual Prediction: {rmse}\")\n",
        "\n",
        "    # Plot results\n",
        "    plot_3d(X_test, y_test, y_pred)\n",
        "    \n",
        "    # Plot results for a specific file\n",
        "    for i in range(min(9, len(test_files))):\n",
        "        specific_file = test_files[i]\n",
        "        specific_file_name = os.path.basename(specific_file)\n",
        "        specific_data = pd.read_csv(specific_file)\n",
        "        specific_features = specific_data[['speed', 'acceleration']]\n",
        "        scaler = StandardScaler()\n",
        "        specific_features_scaled = scaler.fit_transform(specific_features)\n",
        "        specific_dtest = xgb.DMatrix(np.column_stack((specific_data['speed'].to_numpy(), specific_features_scaled)))\n",
        "        specific_y_pred = model.predict(specific_dtest)\n",
        "        plot_full_time_series(specific_data, specific_y_pred, specific_file_name)\n",
        "    \"\"\"\n",
        "    # Save model\n",
        "    parent_dir = os.path.dirname(base_dir)\n",
        "    model.save_model(os.path.join(parent_dir, 'Power_model_XGBoost.json'))\n",
        "    \"\"\"\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
