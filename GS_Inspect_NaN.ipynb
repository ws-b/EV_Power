{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T00:51:15.834353Z",
     "start_time": "2024-06-07T00:50:25.891867Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import dask.bag as db\n",
    "from dask.distributed import Client\n",
    "import shutil\n",
    "\n",
    "# Define the directories and output path\n",
    "directory = r'D:\\SamsungSTF\\Processed_Data\\TripByTrip'\n",
    "output_path = r'C:\\Users\\BSL\\Desktop\\result_files_nan.csv'\n",
    "destination_directory = r'D:\\SamsungSTF\\Processed_Data\\MissingData_NAN'\n",
    "\n",
    "# Function to check if a file contains NaN values in specified columns\n",
    "def check_file(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if any(col in df.columns for col in ['speed', 'acceleration', 'Power_IV', 'Power']):\n",
    "            if df[['speed', 'acceleration', 'Power_IV', 'Power']].isnull().any().any():\n",
    "                return os.path.basename(filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filepath}: {e}\")\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    # Start a Dask client with a specified port\n",
    "    client = Client(dashboard_address=':7869')  # You can choose any available port here\n",
    "\n",
    "    # Get list of all CSV files in the directory\n",
    "    csv_files = [os.path.join(directory, filename) for filename in os.listdir(directory) if filename.endswith(\".csv\")]\n",
    "\n",
    "    # Create a Dask bag of the file paths\n",
    "    file_bag = db.from_sequence(csv_files, npartitions=32)\n",
    "    \n",
    "    # Map the check_file function to the file paths\n",
    "    results = file_bag.map(check_file).compute()\n",
    "\n",
    "    # Filter out None results\n",
    "    files_with_nan_values = [result for result in results if result]\n",
    "    files_with_nan_values.sort()\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    result_df = pd.DataFrame(files_with_nan_values, columns=['filename'])\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Move files with NaN values to the destination directory\n",
    "    for filename in files_with_nan_values:\n",
    "        source_path = os.path.join(directory, filename)\n",
    "        if not os.path.exists(destination_directory):\n",
    "            os.makedirs(destination_directory)\n",
    "        destination_path = os.path.join(destination_directory, filename)\n",
    "        shutil.move(source_path, destination_path)\n",
    "    \n",
    "    client.close()\n",
    "    return files_with_nan_values\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_files = main()\n",
    "    print(result_files)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BSL\\AppData\\Roaming\\Python\\Python312\\site-packages\\distributed\\node.py:182: UserWarning: Port 7869 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 9008 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bms_01241124056-2024-04-trip-2.csv', 'bms_01241228122-2023-02-trip-17.csv', 'bms_01241228122-2023-02-trip-24.csv', 'bms_01241228122-2023-02-trip-37.csv', 'bms_01241228122-2023-03-trip-53.csv', 'bms_01241228122-2023-05-trip-50.csv', 'bms_01241228122-2023-06-trip-25.csv', 'bms_01241228122-2023-09-trip-11.csv', 'bms_01241228122-2023-12-trip-27.csv', 'bms_01241228151-2023-06-trip-30.csv', 'bms_01241228154-2023-02-trip-15.csv', 'bms_01241228154-2023-03-trip-31.csv', 'bms_01241228154-2023-07-trip-7.csv', 'bms_01241228154-2023-08-trip-26.csv', 'bms_01241228154-2023-08-trip-3.csv', 'bms_01241228154-2023-08-trip-41.csv', 'bms_01241228154-2023-09-trip-10.csv', 'bms_01241228154-2023-09-trip-21.csv', 'bms_01241228156-2023-02-trip-12.csv', 'bms_01241228156-2023-02-trip-27.csv', 'bms_01241228156-2023-02-trip-30.csv', 'bms_01241228156-2023-02-trip-9.csv', 'bms_01241228156-2023-05-trip-27.csv', 'bms_01241228156-2023-06-trip-24.csv', 'bms_01241228156-2023-08-trip-43.csv', 'bms_01241228156-2023-09-trip-13.csv', 'bms_01241228197-2023-05-trip-25.csv', 'bms_01241228197-2023-08-trip-28.csv', 'bms_01241228204-2023-07-trip-58.csv', 'bms_altitude_01241228149-2023-10-trip-80.csv', 'bms_altitude_01241228149-2024-04-trip-55.csv', 'bms_altitude_01241248726-2023-08-trip-21.csv', 'bms_altitude_01241248726-2023-08-trip-32.csv', 'bms_altitude_01241248726-2023-12-trip-18.csv', 'bms_altitude_01241364621-2023-09-trip-35.csv', 'bms_altitude_01241364621-2024-01-trip-24.csv', 'bms_altitude_01241364621-2024-01-trip-25.csv', 'bms_altitude_01241364621-2024-02-trip-24.csv', 'bms_altitude_01241364621-2024-02-trip-41.csv', 'bms_altitude_01241364621-2024-02-trip-48.csv', 'bms_altitude_01241364621-2024-03-trip-19.csv']\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
